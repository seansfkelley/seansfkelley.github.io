---
layout: post
title: A Theory on Regulating Social Media
---

Social media has been on peoples' minds with over the last few years, more so in the last few months, and even _more_ so even in the last few days. Regardless of where you stand on Twitter moderation, or the general lack thereof on Facebook, or the continued existence of Parler, surely you agree that _something_ is broken. Nobody is happy with the way things are working except those who stand to make money from it.

While I am relieved to never again have to hear about Twitter as the mouthpiece of a sitting president[^1], my first thought after the banhammer came down is nicely summarized by this quote:

> "We understand the desire to permanently suspend him now, but it should concern everyone when companies like Facebook and Twitter wield the unchecked power to remove people from platforms that have become indispensable for the speech of billions," said Kate Ruane, an A.C.L.U. lawyer. "President Trump can turn to his press team or Fox News to communicate with the public, but others -- like the many Black, brown and L.G.B.T.Q. activists who have been censored by social media companies -- will not have that luxury."

// TODO: format block quotes
// TODO: figure out the source of the original quote and cite it

// TODO: talk about why I like the quote before I talk about what it reveals that I think is wrong (which is what's below)

_"...platforms that have become indispensable for the speech of billions"._ To be beholden to the whims of a for-profit company for access to a wide audience is a concerning thought. Or rather, it sounds like it is, but it's been generally accepted as both unavaoidable and reasonable for hundreds of years in the form of newspapers, radio, and television.

The real underlying problem with social media as it pertains to this type of speech is that we, the general public and users, have a historically unaware and unreasonable opinion on how this type of speech ought to work. Put another way: _why do we think we have the right to instantaneously publish our thoughts to potentially billions of others?_ There is no precedent for that, nor is it self-evidently good or useful. Why is Twitter "indispensable"?

// TODO: Put in an argument for why the following system should exist.

The internet is a fractal hodge-podge. At every level, in every (sub)system, physically, digitally, legally, it's just a bunch of things that seem to work mashed up into an incredible and surprisingly robust whole.

Legally speaking, regulation is all over the place. The FCC of late has been swingly violently from one side of the aisle to the other, GDPR and the CCPA are trying to control at least some emergent behaviors, and social media is a modern Wild West. There's no holistic approach handling which systems exist, why, and what their role is.

My proposal focuses on three main tiers and has some corollary observations afterwards. Something something about this being only about producers of content.

1. **Access.** Access to the internet should always be available. More specifically:

    - ISPs cannot be held liable for the bytes that travel their network, and furthermore, they should not be allowed to discriminate those bytes. Net neutrality, for short. // TODO: Look up the more specific definition of net neutrality and mmake sure I'm not underselling it.
    - Domain registrars should not be held liable for the content of the domains registered with them.
    - Some domain registrars should not be allowed to discriminate against registrants based on the content of the site they host. Call these the "public" registrars.
    - Some domain registrars can disallow certain registrants, but only on the grounds of value-neutral judgements, as they currently do, such by nationality or area of focus. Call these the "private" registrars.

  This is all that I consider mandatory to allow producing content on the internet. If you want to product a hate site, you can, with these rules, but you have to do the rest of the work yourself: buy a physical server, set up we hosting software, pay bandwidth bills.

2. **Hosting.** Hosting companies like AWS cannot be held liable for the content that they host. However, they _are_ allowed to discriminate against that content. Usually, this is called "terms of service".

  This is all that I consider necessary for someone to start politically-neutral web sites, which are the vast majority on the internet: ecommerce, blogs, forums, etc.

3. **Publishing.** Publishing content is defined as "allowing any old schmuck to blast their opinions out to the wider internet with as little as keyboard and couple clicks". Publishers are legally liable for the content on their network in the same way that traditional media publishers are.

The idea here is that you have a right to be able to produce content on the internet, but you do _not_ have a right to a wide audience. That is a privilege that for-profit companies may provide.

// TODO: Include some thoughts on public access domains/hosting/etc.

// TODO: Talk also about anonimity: are you allowed tobe anonymous if you use a public registrar?

// TODO: Talk about private 1:1 messages (not publishing).

[^1]: Time will tell, but one can hope.

"self-evidently good or useful": how about an aside on Facebook thinking that connecting the world is objectively a good and correct thing to do?

compare to traditional media: TV has public access channels, newspaper have editorials, but you don't have a right to blast your opinion to everyone, which is the problem with the internet now

outline

- stumbleupon
- free domains regulated by the government a la public access TV
- no/limited search engines
- social media only for "friends" (you aren't allowed to publish to billions of people)
- private hosts can do whatever
- public hosts of others' content are regulated like publishers

what are the things that make the internet great?

- low barrier to entry
-

With the tide slowly turning against Facebook (and, to lesser degrees, Google and Twitter), I've started to reflect on how I use the internet, what I do and don't value about it, and how to prevent some of the bad tendencies we've started to see.

I'm not an expert on social systems and communities by any means, just someone with an interest in an internet that serves people more than corporations and nation-states. Furthermore, I didn't want to be constrained by existing legal systems and decisions, only by technical ones. In that way, this might be a little impractical to achieve in any short time frame, or at all.

Many of the ideas here grew out of a train of thought focusing on regulating social media companies. I'm not intimately familiar with Section 230 and indeed, for better or for worse, I'm going to more or less ignore it except as it provides explanatory power.

The basic argument was as follows:

- social media companies exercise direct and strong control over what content reaches users -- ranking algorithms, suggested content and at times, censorship
