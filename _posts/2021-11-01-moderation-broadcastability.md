---
layout: post
title: Facebook is Too Big to Exist
# disable the excerpt because it picks the image caption and I can't choose anything more specific
excerpt_separator: ""
last_modified_at: 2023-10-07
---

<figure>
<!-- I wanted to call this post facebook-moderation-broadcastability but then uBlock Origin saw `facebook` in the URL and blocked it. :( -->
<img src="/assets/moderation-broadcastability/street-art.jpg" alt="Street art showing Facebook logo as a cigarette." />
<figcaption markdown="1">
In an excellent happenstance, I found this on the street while drafting this post. It's now gone, but maybe there's something equally optionated there instead. [51° 31' 12.89" N, 0° 4' 11.65" W](https://www.google.com/maps/@51.5202684,-0.0699052,2a,75y,205.43h,81.72t,0.49r/data=!3m6!1e1!3m4!1sYtB3iBiH61iUjZhV3V7fbQ!2e0!7i13312!8i6656?entry=ttu)
</figcaption>
</figure>

The stream of bad press for ~~Facebook~~ ~~Meta~~ Facebook[^1] has been going steady for a while now.[^2] As someone who finally deleted my Facebook account some time around or after the Cambridge Analytica scandal, I'd say: deservedly so.

To the extent that I continue to think about Facebook, I've been trying on-and-off to find a succinct and satisfying explanation for why Facebook, in particular, has become so influential and so toxic. To be sure, it's not alone -- ~~Twitter~~ ~~X~~ Twitter comes to mind -- but it seems like the worst offender. What did/does it do that made it so different and so much more problematic than its competitors and predecessors?

The problem, as I see it, is that Facebook is the first to simultaneously enable, on the truly ridiculous scale of its user base, both:

- _non-moderation_, or, the ability to say whatever you want
- _broadcastability_, or, the ability to send what you say to a huge audience

That Facebook enables these together is hopefully obvious, their [weak attempts at "moderation"](https://apnews.com/article/myanmar-business-d55600bf3f683d863682c0480a298a0a) notwithstanding. Perhaps less obvious is that a functional separation between these two has historically existed, but I think that is the case.

(Non-)moderation and broadcastability are both a spectrum, and they are largely inverses. As one builds a big idea from a kitchen table conversation, though self-published flyers and town paper letters-to-the-editor up to national TV news interviews, one is subject to increasing moderation. To be granted access to the TV audience is to have your idea vetted as "something worth saying", for some definition of "worth" that (used to) exclude the kind of stuff on Facebook that is prompting this national conversation.[^3]

The mixing of non-moderation and broadcastability on Facebook plays out mostly in the blurrily public/private zones of Groups, Timeline and perhaps Events. An incendiary post from your weird uncle gets reshared by your other weird uncle on the other side. They know each other, sure, but it's not the kind of thing they would have brought up casually at the next family gathering. Even if they had, the passive audience would be significantly smaller. Timeline is "private" enough that they feel comfortable sharing, but public enough that hundreds or thousands of bystanders are caught in the blast radius of negativity -- all with the effort of a single click on "Reshare".

Such interactions are the lifeblood of Facebook -- engagement translates directly to revenue -- hence the endless tweaking of the ever-inscrutable Algorithm to encourage them. Leading up to the 2020 election, we all learned for the first time of something that a lot of us suspected: Facebook knowingly exercises [direct control](https://usatoday.com/story/tech/2020/11/05/facebook-election-misinformation-crackdown-emergency-measures-trump/6182001002/) over the degree of both moderation and broadcast of posts, dampening them only in emergencies.

Facebook isn't the only entity that exercises such malicious, or at least, spectacularly tone-deaf control over the audience they have cultivated. Yelp's questionable "editorial" processes frequently get them criticized as abusive, to the degree that they have a [support page](https://www.yelp-support.com/article/Does-Yelp-extort-small-businesses) describing how they supposedly _don't_ extort businesses. Even a misguided or rogue moderator in an enthusiasts' forum can single-handedly derail it.

These sites, and countless others like them, exist because of and are protected by the now (in?)famous Section 230:

> No provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider.[^4]

That's the full text of Section 230(c)(1), and is the heart of the Communications Decency Act of 1996.

As it stands, Facebook, Yelp and all the others are still well within their (current) rights to manipulate content on their platforms.[^5] I would go so far as to say that Section 230 all but invites their creation and consequent manipulative behavior. After all, if you aren't responsible for moderating what your users post and you can cherry-pick what should be broadcast, why _wouldn't_ a for-profit ad-driven company steer towards maximum engagement?

It's clear, then, that the only way out of this predicament is with a change to Section 230.[^6]

Some of those who benefit from the Section 230-protected intertubes have been advocating for full repeal, which is throwing the baby out with the bathwater. My blissfully Facebook-free internet life would be much the worse if almost every other site I frequented were forced to choose between taking on liability for their users or simply shutting down. Instead, I'd like to see a sliding scale of sorts that allows the small-time sites to stay unencumbered but mandates some degree of responsibility to ones with a larger blast radius.

Others say the problem can be solved by spinning off, say, Instagram. In the absence of regulatory changes, an AT&T-style breakup (regardless of whether it's along horizontal or vertical lines) would merely waste everyone's time. Without a paying user base[^7] or significant physical infrastructure to induce drag, the reconsolidation would be swift. Instead, I'd like to see some kind of forced decentralization of Timeline, Groups and their ilk, which is where the damage is really done. Prying those apart is unlikely to happen in such a breakup, however.

We've been trained to expect non-moderation and broadcastability almost as an inherent right of using the internet, but this is a destructive aberration. A combination of forced decentralization (to control broadcastability) and transference of responsibility back to the platforms (to encourage non-negligible moderation) will be messy, painful and awkward. Our collective Facebook-trained expectations may make it politically difficult. But I find it hard to believe that the cure could be worse than the disease, and the disease is not going away by itself -- in fact, it's Metastasizing.[^8]

-------------------------------------------------------------------------------

If you'd like to read more like this, check out:

- [If your website's full of assholes, it's your fault](https://anildash.com/2011/07/20/if_your_websites_full_of_assholes_its_your_fault-2/) -- Anil Dash
- [People Aren’t Meant to Talk This Much](https://www.theatlantic.com/technology/archive/2021/10/fix-facebook-making-it-more-like-google/620456/) -- The Atlantic (and at times eerily similar to this post)
- [The Largest Autocracy on Earth](https://www.theatlantic.com/magazine/archive/2021/11/facebook-authoritarian-hostile-foreign-power/620168/) -- The Atlantic (originally published as _Facebookland_, and yes, I like the Atlantic)

_Updated 2022-01-07: added another link to the reading list._

-------------------------------------------------------------------------------

{% include next-previous.html %}

-------------------------------------------------------------------------------

[^1]: I was drafting this post in the weeks leading up to The Announcement. I don't think the name Facebook is going any any time soon, and I don't think a regulation-dodging rename makes any of these observations less relevant. So I'll continue to use the name Facebook.
[^2]: Since at least [{{ "2021-01-06" | date: site.date_format }}](https://en.wikipedia.org/wiki/2021_United_States_Capitol_attack), if not [{{ "2018-03-17" | date: site.date_format }}](https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal).
[^3]: I realize there are other problems with old-school mass-media gatekeeping, but let's stay on topic for now.
[^4]: Via [Cornell Law School](https://www.law.cornell.edu/uscode/text/47/230).
[^5]: There isn't, by the way, [a platform-publisher distinction](https://www.eff.org/deeplinks/2020/12/publisher-or-platform-it-doesnt-matter) or any [requirement of neutrality towards content](https://www.eff.org/deeplinks/2018/04/no-section-230-does-not-require-platforms-be-neutral), as is sometimes claimed.
[^6]: This is probably the only time I'll say this in my entire life, but, to Mark Zuckerberg's credit, he has [asked for regulation](https://www.huffingtonpost.com/entry/mark-zuckerberg-facebook-regulation_n_5ab400dae4b054d118e0eac5) in the past.
[^7]: Advertisers are the _customers_, but regular people are the _users_.
[^8]: I'm only a little sorry.
