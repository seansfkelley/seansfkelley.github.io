---
layout: post
title: Thoughts on Section 230 and the Corporate Death Penalty
tags: opinion
hidden: true # publishable draft; remember to update the original to link here
---

In a [previous post]({% post_url 2021-11-01-moderation-broadcastability %}) I made a mealy-mouthed argument that implied, among other things, that Facebook was somehow inherently talented at tearing apart our social fabric, and that [Section 230](https://en.wikipedia.org/wiki/Section_230), or maybe Facebook, or Twitter, or maybe actually Section 230, was the root cause of the problem.

As I have had time in the years since to sit with Twitter, Snapchat, TikTok and the quickly eroding journalistic standards of most traditional media, especially in the aftermath of Covid and while waiting for _The Orange Man II: This Time It's Even More Personal Than Last Time_ to be over, it's become clear to me that while Facebook enjoys a monopoly on certain types of social fabric destruction more or less as an accident of history, this is a fundamental issue with "lots of people talking to lots of other people on the internet completely unfiltered", more commonly known as "social media".

Section 230 contributes. Here it is in its entirety:

> No provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider.

In other words, internet companies aren't liable for things their users say using them. Generally.

With that background established, here is my current take:

- Section 230 has its heart in the right place, but naively relies too much on an implied sense of common decency.
- Facebook is the vehicle by which we have learned and continue to learn about the above, but only because it was (and still often is) in the "right" place at the "right" time, not because of e.g. a uniquely visionary founder.
- Corporations that create massive problems they are unable to solve should be commensurately penalized, up to and including the [corporate death penalty](https://en.wikipedia.org/wiki/Judicial_dissolution).

Just to get ahead of some potential tangents, I don't want to talk about:

- The near-total elimination of our collective attention span.[^attention-span]
- Our collective desensitization towards increasingly violent media.[^desensitization]

[^attention-span]: I got my fill of this during the 1990s moral panic over the early internet. There is historical precedent for this type of hand-wringing [going back to at least the invention of the printing press](https://en.wikipedia.org/wiki/Information_overload#History). I think the point on attention span is largely, though not entirely, illegitimate. Only when it rises to the level of people being unable to sustain a coherent conversation or argument -- be it at the kitchen table or over broadcast media -- does it become a problem worth addressing. If you want to waste your life on shallow memes you won't remember five minutes from now, that's your prerogative.

[^desensitization]: My take here is largely in line with that of [^attention-span], especially in regards to the 1990s moral panic, but this time about video games. Analogously to attention spans and coherent conversation, I think it's only a problem when it spills over into the real world. Which it very much has, to be clear, but let's be sure that we blame, in priority order, (1) those committing the violence, (2) those inciting others to violence, (3) weapons manufacturers, when relevant, who make and sell _machines designed specifically and exclusively for killing other people_ and (4) easily-abused systems intentionally designed to do violence.

Let's tackle this in order.

---------------------------------------

> Section 230 has its heart in the right place...

The EFF has [a great article on the non-distinction between "publisher" and "platform"](https://www.eff.org/deeplinks/2020/12/publisher-or-platform-it-doesnt-matter)[^hecklers-veto] that is often invoked in the context of Section 230 to protect media companies by categorizing them as a "platform" and not a "publisher". This is, if you didn't read that whole EFF article, irrelevant, and misunderstands the intent behind Section 230. Aggressively eliding to get to the point (emphasis original):

[^hecklers-veto]: This article also introduced me to the phrase "heckler's veto", which is an _excellent_ pithy title for what amounts to tattling to Big Tech when someone says something you don't like.

> Historically, there is some legal distinction between "publishers" and more passive "distributors" of others' speech \[...\] "distributor liability" applied to those like booksellers \[...\] who merely served as fairly passive conduits for others' speech \[...\]. Because one was treated a bit better if they were a passive distributor, the law actually disincentivized editing, curation, or reviewing content for any reason. \[...\] Former Rep. Chris Cox, one of the co-authors of Section 230, recalls finding it "surpassingly stupid" that before Section 230, courts effectively disincentivized platforms from engaging in _any_ speech moderation.

Section 230 was changed to provide cover specifically so that moderation could happen, since before these changes internet companies were liable for everything as soon as they touched anything.

---------------------------------------

> ...but naively relies too much on an implied sense of common decency.

The EFF has another great article stressing that [while Section 230 actually _shields_ media companies should they engage in aggressive and/or biased content moderation](https://www.eff.org/deeplinks/2018/04/no-section-230-does-not-require-platforms-be-neutral), they obviously do not. While they _can_ be bothered to rouse themselves enough to (try to) eliminate, say, child pornography, [not spreading pro-genocide propaganda](https://apnews.com/article/myanmar-business-d55600bf3f683d863682c0480a298a0a) is evidently asking too much.

Rage generates clicks, clicks are engagement, engagement is advertising dollars. Facebook, specifically, [volunteered at least once that it intentionally manipulates the ever-inscrutable Algorithm](https://usatoday.com/story/tech/2020/11/05/facebook-election-misinformation-crackdown-emergency-measures-trump/6182001002/) to put its thumb on the scale. You can rest assured Facebook does this regularly to steer users towards whatever maximizes advertising revenue -- generally, the rage-bait _du jour_ -- as there is [no real punishment for abusing your position of power](https://www.cnbc.com/2025/11/18/meta-wins-ftc-antitrust-trial-that-focused-on-whatsapp-instagram.html) when you get caught beyond [saying "sorry" really loudly](https://www.cnn.com/2018/03/25/europe/facebook-zuckerberg-cambridge-analytica-sorry-ads-newspapers-intl). (More on punishment later.)

The tools are there, but they only use them for public good when it is [politically expedient](https://www.npr.org/2024/12/13/nx-s1-5227874/trump-bezos-zuckerberg-amazon-facebook-open-ai-meta-inauguration-fund)[^tim-cook-debases-himself] to do so.

[^tim-cook-debases-himself]: This isn't the [most egregious example of a tech company prostrating itself](https://www.theverge.com/news/737757/apple-president-donald-trump-ceo-tim-cook-glass-corning) at the orange altar, but it very much still counts.

---------------------------------------

> Facebook is the vehicle by which we have learned and continue to learn about the above, but only because it was (and still often is) in the "right" place at the "right" time, not because of e.g. a uniquely visionary founder.

Facebook is very obviously the first _truly_ successful social media company. It has objectively done a remarkable job staying relevant, as measured purely by market capitalization, despite [spending the GDP of a small country to add legs to their Metaverse's avatars](https://www.wired.com/story/fake-metaverse-good-real-metaverse-bad/).[^snow-crash]

[^snow-crash]: In case you didn't already know, "metaverse" was coined by Neal Stephenson in _Snow Crash_ and is intended to be _satire_. I assume Mark Zuckerberg has figured this out by now.

Facebook, as distinct from Meta, already contains several separate products that compete directly with other companies specializing in only that thing: Groups, Events, Marketplace, and Messenger (before it was spun off to a brand directly under Meta).

It didn't invent any of these ideas, but it's fair to say it introduced a lot of its users to them by refining them and handing them out for free. Even the strategy itself is not novel; this is the same playbook used by Apple, who did not invent the MP3 player, touchscreen smartphone or tablet, but often gets credit for all of them.

In this way, Facebook parlayed success with friends, pokes, likes and the capital-f Feed into being the first company to show everyone what happens when over a billion people can _easily_ -- and that is a key feature that cannot be emphasized enough -- form interest groups with each other, [consequences be damned](https://www.theguardian.com/technology/2018/mar/29/facebook-memo-mission-andrew-bosworth).

---------------------------------------

> Corporations that create massive problems they are unable to solve should be commensurately penalized, up to and including the [corporate death penalty](https://en.wikipedia.org/wiki/Judicial_dissolution).

I stated this intentionally broadly because it is both something I believe in as written, and something that you may consider [more obviously true in other domains](https://en.wikipedia.org/wiki/Deepwater_Horizon). We (try to?) punish companies that dump toxic waste into the environment. If a company _must_ dump toxic waste into the environment as part of its business model, or is so foundationally negligent that it would be prohibitively expensive to reform it, why do we permit such a company to exist? "Shareholder value" should not be a [thought-terminating clich√©](https://en.wikipedia.org/wiki/Thought-terminating_clich%C3%A9); negative externalities for non-shareholders[^non-shareholders] are real and sometimes severe. Corporations _are not_ people and have no right to life.

[^non-shareholders]: Obviously, non-shareholders have no say in how a company functions except either through voting for a government that will impose restrictions on said company, which assumes a functioning regulatory apparatus, or bad publicity, which assumes a common understanding of facts and trustworthy news outlets. Uh oh.

Social media companies escape some deserved scrutiny because it is difficult to measure their negative effects in dollars or lives lost. This is where things start to get thorny, especially because I am not a lawyer, and because "speech" is a lot more loosey-goosey than the relatively cut-and-dried "environmental damage". Given humanity's long history of killing the messenger, it's not immediately obvious how, or even if, media companies _should_ be held liable for the types of various abuses I've already enumerated above.[^hate-speech]

[^hate-speech]: It seems to me that [hate speech is not illegal in the United States](https://en.wikipedia.org/wiki/Matal_v._Tam) though there is some kind of [allowance for punishing speech that incites "imminent lawless action"](https://en.wikipedia.org/wiki/Brandenburg_v._Ohio). More thorns. Also, again, still not a lawyer.

That said, most or all of these aforementioned abuses are only feasible because social media companies exist. _Feasible_ is doing a lot of heavy lifting here; tech companies love to defend their negative effects on the grounds that [whatever the negative thing is, it was always possible, so it's not really relevant that they made it easier](https://www.thetimes.com/uk/technology-uk/article/nick-clegg-algorithms-fake-news-kn0d90hjv). Such a black-and-white worldview is obvious bullshit, but it persists because nobody can put their finger on where, between texting racist screeds to someone else and posting racist screeds that are amplified by thousands of other users, someone besides the poster may be liable. You could call this "diffusion of responsibility as a business model", not that Facebook has any interest in unilaterally suppressing such abuse anyway, because [the phrase "arbiter of truth" sounds scary](https://about.fb.com/news/2017/04/working-to-stop-misinformation-and-false-news/).

I would like us to punish Facebook commensurately to the damage is has obviously done to various societies around the planet -- even ignoring its contributions to the vague but increasing internet-enabled malaise of younger generations that is, again, difficult to quantify. But I do not know on what grounds it is possible.

---------------------------------------

If you've followed me this far, consider these questions:

1. What is the cultural/social value of Facebook?
2. How does Facebook compare to other social media companies on that question? Traditional media? Other, more-personal communication methods?
3. Are Facebook's benefits worth it? Are they that much better than less-abusable services like iMessage or YouTube?
4. Would it be easier to get these benefits from a more-focused competitor with different incentives and avenues for abuse than monolithic, advertising-driven Facebook?

(Where Facebook is a stand-in for any social media company, though nevertheless the best single example.)

---------------------------------------

I want to give my partial answers to these questions specifically for Facebook Events, because it was the only thing I missed after deleting my Facebook account. I hope this will spur some introspection on your part, as well, if the questions haven't already.

1. Facebook Events is an excellent way to plan a gathering of friends. Word-of-mouth, emails, texts, calendar invites are all some combination of unreliable, easily forgotten, spammy and (from the perspective of the event host) too decentralized to be easily managed. Facebook Events made it easy for me and guests to have a single place to check and chat, send reminders and updates, and give the event a bit of personality with banner images and such. In this way, Facebook Events did actually live up to the promise to foster interpersonal connections.
2. At the time I deleted my account, Facebook Events was by far the best way to plan events like this. More-personal communication methods were messy, as mentioned, and traditional media are irrelevant. (Though perhaps if I were planning something like a public rally, they may apply.)
3. The benefits were not worth it, which is why I deleted my Facebook account and ate the cost of it being more difficult to plan and host events. Other media were indeed more annoying to use, but people have been planning events for thousands of years without Facebook, so I muddled through.
4. Last year I learned about [Partiful](https://partiful.com/), which is emphatically better to use than Facebook Events. I already have an implied social network through my phone contacts and these events are all one-offs, so Partiful's focus on ephemeral-ish events managed only with phone numbers and having only the features necessary to actually host an event and give it some personality hits the nail _squarely_ on the head. [Unbundling](https://techcrunch.com/2015/04/18/the-unbundling-of-everything/) Facebook Events is, in my book, a huge win for everyone involved that isn't Facebook, even without considering the merits of removing this category of personal data from Facebook's reach.

{% include common-footer.html %}
